{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/YOLACT_Mobius/blob/main/YOLOv11_cropeyelid_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference YOLOv11 segmentation**\n",
        "\n",
        "https://docs.ultralytics.com/modes/predict/#why-use-ultralytics-yolo-for-inference"
      ],
      "metadata": {
        "id": "VlMmw4BC7_Gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "#driveのマウント\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!git clone https://github.com/ultralytics/ultralytics\n",
        "%cd ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuNkk3_Og-eI",
        "outputId": "75baf15b-ee84-47d0-a369-6329b9ab02ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'ultralytics'...\n",
            "remote: Enumerating objects: 45282, done.\u001b[K\n",
            "remote: Counting objects: 100% (210/210), done.\u001b[K\n",
            "remote: Compressing objects: 100% (114/114), done.\u001b[K\n",
            "remote: Total 45282 (delta 124), reused 165 (delta 95), pack-reused 45072 (from 1)\u001b[K\n",
            "Receiving objects: 100% (45282/45282), 37.84 MiB | 15.57 MiB/s, done.\n",
            "Resolving deltas: 100% (33709/33709), done.\n",
            "/content/ultralytics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**simple inference**"
      ],
      "metadata": {
        "id": "vlnY5eT6Ak0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv11\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#image_path = r\"C:\\CorneAI\\DemoImage\\典型例\\【正常】demo008.BMP\"\n",
        "image_path = r\"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/Segmentation_test_images/Control_adult/1000.jpg\"\n",
        "\n",
        "model = YOLO(\"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/MOBIUS/YOLOv11/best_458epochs.pt\")  # load a pretrained model (recommended for training)\n",
        "results = model(image_path,save=False)\n",
        "\n",
        "# Process results list\n",
        "for result in results:\n",
        "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
        "    masks = result.masks  # Masks object for segmentation masks outputs\n",
        "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
        "    probs = result.probs  # Probs object for classification outputs\n",
        "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
        "    result.show()  # display to screen\n",
        "    result.save(filename=\"result.jpg\")  # save to disk"
      ],
      "metadata": {
        "id": "B6WXf-Dn8E39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "be1Ik-298E6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OMm-BaOk8E70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MW9xX0Rw8E9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#yolov8\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "9V7_-QQt70z_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#yolov8\n",
        "from ultralytics import YOLO\n",
        "#model = YOLO(\"/content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/sample_dataset_for_YOLOv8/last.pt\")\n",
        "#model = YOLO(\"/content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/sample_dataset_for_YOLOv8/last_100epochs.pt\")\n",
        "model = YOLO(\"/content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/sample_dataset_for_YOLOv8/last_new.pt\")\n",
        "\n",
        "\n",
        "# ディレクトリパスを設定\n",
        "image_dir = \"/content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/sample_dataset_for_YOLOv8/images/val\"\n",
        "\n",
        "# ディレクトリ内の画像ファイルを取得\n",
        "image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "img_path = image_files[14]\n",
        "results = model(img_path, save=True, save_txt=True)  # predict on an image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDbmZKV20l4k",
        "outputId": "775a4dd0-439f-4caa-84cd-bc3da881e30b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/sample_dataset_for_YOLOv8/images/val/3_1n_Ll_1.jpg: 384x640 1 eyelid, 1 iris, 1 pupil, 33.3ms\n",
            "Speed: 3.1ms preprocess, 33.3ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Results saved to \u001b[1m/content/ultralytics/runs/segment/predict6\u001b[0m\n",
            "1 label saved to /content/ultralytics/runs/segment/predict6/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 画像を読み込む\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# 結果を取得\n",
        "result = results[0]\n",
        "\n",
        "# マスクとボックスを取得\n",
        "masks = result.masks.data.cpu().numpy()\n",
        "boxes = result.boxes.data.cpu().numpy()\n",
        "\n",
        "# 各クラスに対して異なる色を設定\n",
        "colors = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]  # 赤、緑、青\n",
        "\n",
        "# セグメンテーションマスクを重ねる\n",
        "for i, mask in enumerate(masks):\n",
        "    color = colors[int(boxes[i, 5]) % len(colors)]\n",
        "    mask = mask.astype(np.uint8) * 255\n",
        "\n",
        "    # マスクを元の画像のサイズにリサイズ\n",
        "    mask = cv2.resize(mask, (img.shape[1], img.shape[0]))\n",
        "\n",
        "    colored_mask = np.zeros((img.shape[0], img.shape[1], 3), dtype=np.uint8)\n",
        "    colored_mask[mask > 0] = color\n",
        "\n",
        "    # マスクを画像にブレンド (50%の透過度)\n",
        "    img = cv2.addWeighted(img, 1, colored_mask, 0.5, 0)\n",
        "\n",
        "# バウンディングボックスを描画\n",
        "for box in boxes:\n",
        "    x1, y1, x2, y2 = map(int, box[:4])\n",
        "    cls = int(box[5])\n",
        "    cv2.rectangle(img, (x1, y1), (x2, y2), colors[cls % len(colors)], 2)\n",
        "\n",
        "# 結果を表示\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title('YOLOv8 Segmentation Result')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "FgWgjqoPzL92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Training**"
      ],
      "metadata": {
        "id": "LxbGcK9PBmer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "LiixEIw5Brcr",
        "outputId": "ec0773a7-1ec6-42cd-b234-c0b439145b29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CITATION.cff\t docker  examples  mkdocs.yml\t   README.md\t    runs   ultralytics\n",
            "CONTRIBUTING.md  docs\t LICENSE   pyproject.toml  README.zh-CN.md  tests\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yaml_path = '/content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/sample_dataset_for_YOLOv8/data.yaml'\n",
        "model.train(data=yaml_path, epochs=300, imgsz=640)"
      ],
      "metadata": {
        "id": "6Yo1vXEvBot-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"last.pt\")\n",
        "model.train(resume=True)"
      ],
      "metadata": {
        "id": "SeJuR4edDTdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Inference Maehara's 234 datasets**\n",
        "\n",
        "/content/drive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/フォトスリット_serial\n",
        "\n",
        "/content/drive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/スマホ_serial\n"
      ],
      "metadata": {
        "id": "tyaY5yP9Yzr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ディレクトリパスを指定\n",
        "#image_dir = \"/content/drive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/フォトスリット_serial\"\n",
        "image_dir = \"/content/drive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/スマホ_serial\""
      ],
      "metadata": {
        "id": "xzXOrlkUbgkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#yolov8\n",
        "from ultralytics import YOLO\n",
        "model = YOLO(\"/content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/sample_dataset_for_YOLOv8/last_new.pt\")\n",
        "\n",
        "# ディレクトリ内の画像ファイルを取得\n",
        "image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "img_path = image_files[24]\n",
        "results = model(img_path, save=True, save_txt=True)  # predict on an image\n"
      ],
      "metadata": {
        "id": "seLuGr-zcovj",
        "outputId": "1f4a84b2-1c0d-473c-e613-6aaaa158c20c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/研究/進行中の研究/角膜スマートフォンAIプロジェクト/前原の240問/スマホ_serial/43.jpg: 640x640 1 eyelid, 1 iris, 1 pupil, 11.2ms\n",
            "Speed: 1.9ms preprocess, 11.2ms inference, 2.5ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m/content/ultralytics/runs/segment/predict22\u001b[0m\n",
            "1 label saved to /content/ultralytics/runs/segment/predict22/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "def extract_iris_region(img, results):\n",
        "    # Find the iris mask\n",
        "    iris_mask = None\n",
        "    for i, mask in enumerate(results.masks.data):\n",
        "        if results.names[int(results.boxes.cls[i])] == 'iris':\n",
        "            iris_mask = mask.cpu().numpy()\n",
        "            break\n",
        "\n",
        "    if iris_mask is None:\n",
        "        print(\"No iris detected in the image.\")\n",
        "        return None\n",
        "\n",
        "    # Create a binary mask\n",
        "    binary_mask = (iris_mask > 0).astype(np.uint8)\n",
        "\n",
        "    # Find contours of the iris\n",
        "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    if not contours:\n",
        "        print(\"No contours found for the iris.\")\n",
        "        return None\n",
        "\n",
        "    # Get the largest contour (iris outer boundary)\n",
        "    largest_contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "    # Create a mask for the iris region\n",
        "    iris_region_mask = np.zeros_like(binary_mask)\n",
        "    cv2.drawContours(iris_region_mask, [largest_contour], 0, 1, -1)\n",
        "\n",
        "    # Create a black background image\n",
        "    black_bg = np.zeros_like(img)\n",
        "\n",
        "    # Apply the mask to the original image\n",
        "    iris_region = cv2.bitwise_and(img, img, mask=iris_region_mask)\n",
        "\n",
        "    # Combine the iris region with the black background\n",
        "    result = cv2.add(black_bg, iris_region)\n",
        "\n",
        "    return result\n",
        "\n",
        "# Load the image\n",
        "img = cv2.imread(img_path)\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Get the iris region\n",
        "iris_extracted = extract_iris_region(img_rgb, results[0])\n",
        "\n",
        "if iris_extracted is not None:\n",
        "    # Display the original image and the extracted iris region\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
        "\n",
        "    ax1.imshow(img_rgb)\n",
        "    ax1.set_title('Original Image')\n",
        "    ax1.axis('off')\n",
        "\n",
        "    ax2.imshow(iris_extracted)\n",
        "    ax2.set_title('Extracted Iris Region')\n",
        "    ax2.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Failed to extract the iris region.\")"
      ],
      "metadata": {
        "id": "2U565vdVcoy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y7uKQ9gqco03"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}