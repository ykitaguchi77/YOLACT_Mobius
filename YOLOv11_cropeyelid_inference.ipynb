{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/YOLACT_Mobius/blob/main/YOLOv11_cropeyelid_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference YOLOv11 segmentation**\n",
        "\n",
        "https://docs.ultralytics.com/modes/predict/#why-use-ultralytics-yolo-for-inference"
      ],
      "metadata": {
        "id": "VlMmw4BC7_Gm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "#driveのマウント\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!git clone https://github.com/ultralytics/ultralytics\n",
        "%cd ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuNkk3_Og-eI",
        "outputId": "64992c64-69a6-473c-8fa9-d9ec272f0cce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Cloning into 'ultralytics'...\n",
            "remote: Enumerating objects: 45290, done.\u001b[K\n",
            "remote: Counting objects: 100% (220/220), done.\u001b[K\n",
            "remote: Compressing objects: 100% (121/121), done.\u001b[K\n",
            "remote: Total 45290 (delta 129), reused 165 (delta 98), pack-reused 45070 (from 1)\u001b[K\n",
            "Receiving objects: 100% (45290/45290), 37.84 MiB | 26.20 MiB/s, done.\n",
            "Resolving deltas: 100% (33706/33706), done.\n",
            "/content/ultralytics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**simple inference**"
      ],
      "metadata": {
        "id": "vlnY5eT6Ak0k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv11\n",
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#image_path = r\"C:\\CorneAI\\DemoImage\\典型例\\【正常】demo008.BMP\"\n",
        "image_path = r\"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/Segmentation_test_images/Control_adult/1000.jpg\"\n",
        "\n",
        "model = YOLO(\"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/MOBIUS/YOLOv11/best_458epochs.pt\")  # load a pretrained model (recommended for training)\n",
        "results = model(image_path,save=False)\n",
        "\n",
        "# Process results list\n",
        "for result in results:\n",
        "    boxes = result.boxes  # Boxes object for bounding box outputs\n",
        "    masks = result.masks  # Masks object for segmentation masks outputs\n",
        "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
        "    probs = result.probs  # Probs object for classification outputs\n",
        "    obb = result.obb  # Oriented boxes object for OBB outputs\n",
        "    result.show()  # display to screen\n",
        "    result.save(filename=\"result.jpg\")  # save to disk"
      ],
      "metadata": {
        "id": "B6WXf-Dn8E39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 元画像と横並びで表示\n",
        "\n",
        "from ultralytics import YOLO\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_single_image(image_path, model_path):\n",
        "    # モデルの読み込み\n",
        "    model = YOLO(model_path)\n",
        "\n",
        "    # 画像の読み込み\n",
        "    original_img = cv2.imread(image_path)\n",
        "    if original_img is None:\n",
        "        print(f\"Failed to load image: {image_path}\")\n",
        "        return\n",
        "\n",
        "    # 推論の実行\n",
        "    results = model(original_img)\n",
        "\n",
        "    # マスクの描画（ラベルなし）\n",
        "    predicted_img = results[0].plot(labels=False, boxes=False)\n",
        "\n",
        "    # 画像のサイズを揃える\n",
        "    h1, w1 = original_img.shape[:2]\n",
        "    h2, w2 = predicted_img.shape[:2]\n",
        "\n",
        "    max_h = max(h1, h2)\n",
        "    max_w = max(w1, w2)\n",
        "\n",
        "    # パディング\n",
        "    padded_original = np.zeros((max_h, max_w, 3), dtype=np.uint8)\n",
        "    padded_predicted = np.zeros((max_h, max_w, 3), dtype=np.uint8)\n",
        "\n",
        "    padded_original[:h1, :w1] = original_img\n",
        "    padded_predicted[:h2, :w2] = predicted_img\n",
        "\n",
        "    # 画像を横に連結\n",
        "    combined_img = np.hstack((padded_original, padded_predicted))\n",
        "\n",
        "    # Matplotlibで表示\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    plt.imshow(cv2.cvtColor(combined_img, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    # 凡例を追加（画像と同じ色を使用）\n",
        "    legend_elements = [\n",
        "        plt.Rectangle((0, 0), 1, 1, fc=(0/255, 0/255, 255/255), alpha=0.6, label='eyelid'),     # 青\n",
        "        plt.Rectangle((0, 0), 1, 1, fc=(64/255, 224/255, 208/255), alpha=0.6, label='iris'),    # ターコイズ\n",
        "        plt.Rectangle((0, 0), 1, 1, fc=(128/255, 128/255, 128/255), alpha=0.6, label='pupil')   # グレー\n",
        "    ]\n",
        "\n",
        "    plt.legend(\n",
        "        handles=legend_elements,\n",
        "        loc='upper right',\n",
        "        bbox_to_anchor=(0.98, 0.98),\n",
        "        fontsize=12,\n",
        "        framealpha=0.8\n",
        "    )\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# パラメータの設定\n",
        "model_path = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/MOBIUS/YOLOv11/best_458epochs.pt\"\n",
        "image_path = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/Segmentation_test_images/Control_adult/1000.jpg\"\n",
        "\n",
        "# 実行\n",
        "display_single_image(image_path, model_path)"
      ],
      "metadata": {
        "id": "be1Ik-298E6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Eyecrop**\n",
        "\n",
        "Haarcascadeで眼周囲を切り抜き（15%マージン）して保存"
      ],
      "metadata": {
        "id": "iriNSYl5EKvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Haarcascedeを用いてシンプルに切り抜き\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# カスケードファイルのパス\n",
        "eye_cascade_path = '/content/drive/My Drive/Deep_learning/haarcascade_eye.xml'\n",
        "\n",
        "# カスケード分類器の特徴量取得\n",
        "eye_cascade = cv2.CascadeClassifier(eye_cascade_path)\n",
        "\n",
        "orig_dir = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/Segmentation_test_images\"\n",
        "dst_dir = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/Segmentation_cropped_images\"\n",
        "\n",
        "# すべてのサブディレクトリを含めて.jpg画像を検索\n",
        "files = glob.glob(os.path.join(orig_dir, \"**/*.jpg\"), recursive=True)\n",
        "\n",
        "for file_path in files:\n",
        "    # 入力ファイルのパス構造を解析\n",
        "    relative_path = os.path.relpath(file_path, orig_dir)\n",
        "    parent_dir = os.path.dirname(relative_path)\n",
        "    id = os.path.splitext(os.path.basename(file_path))[0]\n",
        "\n",
        "    # 出力ディレクトリのパスを作成\n",
        "    out_images_dir = os.path.join(dst_dir, parent_dir, \"images\")\n",
        "    out_labels_dir = os.path.join(dst_dir, parent_dir, \"labels\")\n",
        "\n",
        "    # 出力ディレクトリが存在しない場合は作成\n",
        "    os.makedirs(out_images_dir, exist_ok=True)\n",
        "    os.makedirs(out_labels_dir, exist_ok=True)\n",
        "\n",
        "    img = cv2.imread(file_path)\n",
        "\n",
        "    if img is None:\n",
        "        print(f\"Failed to read image: {file_path}\")\n",
        "        continue\n",
        "\n",
        "    img2 = img.copy()\n",
        "\n",
        "    # 画像グレースケール化\n",
        "    grayscale_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # 300pix以上のもので目に見えるものを抽出\n",
        "    eye_list = eye_cascade.detectMultiScale(grayscale_img, minSize=(300, 300))\n",
        "\n",
        "    # 眼検出判定\n",
        "    if len(eye_list) >= 1:\n",
        "        print(f'画像 {id}: 目が{str(len(eye_list))}個検出されました')\n",
        "    else:\n",
        "        print(f\"画像 {id}: eye detection error\")\n",
        "\n",
        "    # 画像の切り抜きと保存（2個以上検出の時に限る）\n",
        "    if len(eye_list) >= 2:\n",
        "        for (ex, ey, ew, eh) in eye_list:\n",
        "            print(f\"img_width: {img2.shape[1]}\")\n",
        "            print(\"[ex,ey] = %d,%d [ew,eh] = %d,%d\" % (ex, ey, ew, eh))\n",
        "            cv2.rectangle(img2, (ex, ey), (ex + ew, ey + eh), (0, 255, 0), 2)\n",
        "\n",
        "            # Check if coordinates are within the image bounds\n",
        "            ey_start = max(int(ey - 0.15 * eh), 0)\n",
        "            ey_end = min(int(ey + 1.15 * eh), img.shape[0])\n",
        "            ex_start = max(int(ex - 0.15 * ew), 0)\n",
        "            ex_end = min(int(ex + 1.15 * ew), img.shape[1])\n",
        "\n",
        "            # Ensure we have a valid crop area\n",
        "            if ex_start < ex_end and ey_start < ey_end:\n",
        "                img_cropped = img[ey_start: ey_end, ex_start: ex_end]\n",
        "\n",
        "                if ex + eh * 0.5 <= img2.shape[1] / 2:\n",
        "                    side = \"R\"  # 横幅の半分より左にあるのは右眼\n",
        "                else:\n",
        "                    side = \"L\"  # 横幅の半分よりより右にあるのは左眼\n",
        "\n",
        "                print(f\"side: {side}\")\n",
        "                print(\"\")\n",
        "\n",
        "                # 出力ファイル名\n",
        "                output_filename = f\"{id}_{side}\"\n",
        "\n",
        "                # 画像とラベルの保存\n",
        "                cv2.imwrite(os.path.join(out_images_dir, f\"{output_filename}.png\"), img_cropped)\n",
        "\n",
        "                # YOLOのラベルを記載したtextファイルを作成\n",
        "                label_path = os.path.join(out_labels_dir, f\"{output_filename}.txt\")\n",
        "                with open(label_path, \"w\") as f:\n",
        "                    if side == \"R\":\n",
        "                        label = 0\n",
        "                    else:\n",
        "                        label = 1\n",
        "\n",
        "                    # YOLO座標の計算\n",
        "                    yolo_x = (ex_start + ex_end) / (2 * img.shape[1])\n",
        "                    yolo_y = (ey_start + ey_end) / (2 * img.shape[0])\n",
        "                    yolo_w = (ex_end - ex_start) / img.shape[1]\n",
        "                    yolo_h = (ey_end - ey_start) / img.shape[0]\n",
        "\n",
        "                    f.write(f\"{label} {yolo_x:.6f} {yolo_y:.6f} {yolo_w:.6f} {yolo_h:.6f}\")\n",
        "            else:\n",
        "                print(f\"画像 {id}: Invalid crop coordinates. Skipping.\")\n",
        "    else:\n",
        "        print(f\"画像 {id}: Less than 2 eyes detected. Skipping.\")"
      ],
      "metadata": {
        "id": "OMm-BaOk8E70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Haarcascadeで切り抜いた画像をYOLOでさらに切り抜き。切り抜きはうまくいっているがlabelの座標がうまくいっていない\n",
        "\"\"\"\n",
        "To do\n",
        "セグメンテーションを輪郭検出→座標を取る→YOLOv11のlabelに変換\n",
        "\"\"\"\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# カスケードファイルのパス\n",
        "eye_cascade_path = '/content/drive/My Drive/Deep_learning/haarcascade_eye.xml'\n",
        "model_path = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/MOBIUS/YOLOv11/best_458epochs.pt\"\n",
        "\n",
        "# カスケード分類器とYOLOモデルの読み込み\n",
        "eye_cascade = cv2.CascadeClassifier(eye_cascade_path)\n",
        "yolo_model = YOLO(model_path)\n",
        "\n",
        "orig_dir = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/Segmentation_test_images\"\n",
        "dst_dir = \"/content/drive/MyDrive/Deep_learning/Eyelid_segmentation/Segmentation_cropped_images\"\n",
        "\n",
        "# すべてのサブディレクトリを含めて.jpg画像を検索\n",
        "files = glob.glob(os.path.join(orig_dir, \"**/*.jpg\"), recursive=True)\n",
        "\n",
        "for file_path in files:\n",
        "    print(f\"\\n処理中の画像: {file_path}\")\n",
        "\n",
        "    # 入力ファイルのパス構造を解析\n",
        "    relative_path = os.path.relpath(file_path, orig_dir)\n",
        "    parent_dir = os.path.dirname(relative_path)\n",
        "    id = os.path.splitext(os.path.basename(file_path))[0]\n",
        "\n",
        "    # サブディレクトリを含む出力ディレクトリのパスを作成\n",
        "    sub_dir = os.path.join(dst_dir, parent_dir)\n",
        "    if not os.path.exists(sub_dir):\n",
        "        os.makedirs(sub_dir)\n",
        "\n",
        "    # 画像、ラベル、マスク用のサブディレクトリを作成\n",
        "    out_images_dir = os.path.join(sub_dir, \"images\")\n",
        "    out_labels_dir = os.path.join(sub_dir, \"labels\")\n",
        "    out_masks_dir = os.path.join(sub_dir, \"masks\")\n",
        "\n",
        "    # 各サブディレクトリを作成（exist_ok=Trueを追加）\n",
        "    for dir_path in [out_images_dir, out_labels_dir, out_masks_dir]:\n",
        "        os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "    img = cv2.imread(file_path)\n",
        "\n",
        "    if img is None:\n",
        "        print(f\"Failed to read image: {file_path}\")\n",
        "        continue\n",
        "\n",
        "    img2 = img.copy()\n",
        "\n",
        "    # 画像グレースケール化\n",
        "    grayscale_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # 300pix以上のもので目に見えるものを抽出\n",
        "    eye_list = eye_cascade.detectMultiScale(grayscale_img, minSize=(300, 300))\n",
        "\n",
        "    # 眼検出判定\n",
        "    if len(eye_list) >= 1:\n",
        "        print(f'画像 {id}: 目が{str(len(eye_list))}個検出されました')\n",
        "    else:\n",
        "        print(f\"画像 {id}: eye detection error\")\n",
        "\n",
        "    # 画像の切り抜きと保存（2個の場合のみ処理）\n",
        "    if len(eye_list) == 2:\n",
        "        for (haar_x, haar_y, haar_w, haar_h) in eye_list:\n",
        "            print(f\"img_width: {img2.shape[1]}\")\n",
        "            print(\"[haar_x,haar_y] = %d,%d [haar_w,haar_h] = %d,%d\" % (haar_x, haar_y, haar_w, haar_h))\n",
        "\n",
        "            # Check if coordinates are within the image bounds\n",
        "            ey_start = max(int(haar_y - 0.15 * haar_h), 0)\n",
        "            ey_end = min(int(haar_y + 1.15 * haar_h), img.shape[0])\n",
        "            ex_start = max(int(haar_x - 0.15 * haar_w), 0)\n",
        "            ex_end = min(int(haar_x + 1.15 * haar_w), img.shape[1])\n",
        "\n",
        "            # Ensure we have a valid crop area\n",
        "            if ex_start < ex_end and ey_start < ey_end:\n",
        "                img_cropped = img[ey_start: ey_end, ex_start: ex_end]\n",
        "\n",
        "                if haar_x + haar_h * 0.5 <= img2.shape[1] / 2:\n",
        "                    side = \"R\"  # 横幅の半分より左にあるのは右眼\n",
        "                else:\n",
        "                    side = \"L\"  # 横幅の半分よりより右にあるのは左眼\n",
        "\n",
        "                print(f\"side: {side}\")\n",
        "                print(\"\")\n",
        "\n",
        "                # 出力ファイル名\n",
        "                output_filename = f\"{id}_{side}\"\n",
        "\n",
        "                # YOLOv11でinference実行\n",
        "                results = yolo_model(img_cropped)\n",
        "\n",
        "                # YOLOv11の検出結果からeyelidの横幅を取得\n",
        "                eyelid_box = None\n",
        "                for result in results:\n",
        "                    boxes = result.boxes\n",
        "                    for box in boxes:\n",
        "                        cls_id = int(box.cls)\n",
        "                        if cls_id == 0:  # eyelidのクラスID = 0\n",
        "                            yolo_x1, yolo_y1, yolo_x2, yolo_y2 = box.xyxy[0]  # xyxy形式で座標を取得\n",
        "                            yolo_width = yolo_x2 - yolo_x1  # 実際のピクセル幅\n",
        "                            if eyelid_box is None or yolo_width > eyelid_box[2]:\n",
        "                                eyelid_box = (yolo_x1, yolo_y1, yolo_width, yolo_y2 - yolo_y1)\n",
        "\n",
        "                if eyelid_box is not None:\n",
        "                    yolo_x1, yolo_y1, yolo_width, yolo_height = eyelid_box\n",
        "                    # eyelidの横幅を基準に正方形サイズを計算\n",
        "                    square_size = int(yolo_width * 1.5)  # padding 25% × 2 = 50% 増\n",
        "\n",
        "                    # 正方形の中心をeyelidの中心に合わせる\n",
        "                    center_x = yolo_x1 + yolo_width/2\n",
        "                    center_y = yolo_y1 + yolo_height/2\n",
        "\n",
        "                    # 正方形の領域を計算\n",
        "                    square_x1 = int(max(center_x - square_size/2, 0))\n",
        "                    square_y1 = int(max(center_y - square_size/2, 0))\n",
        "                    square_x2 = int(min(square_x1 + square_size, img_cropped.shape[1]))\n",
        "                    square_y2 = int(min(square_y1 + square_size, img_cropped.shape[0]))\n",
        "\n",
        "                    # 正方形領域を切り出し\n",
        "                    img_square = img_cropped[square_y1:square_y2, square_x1:square_x2]\n",
        "\n",
        "                    # もし切り出した領域が正方形でない場合（端の処理）\n",
        "                    actual_size = max(img_square.shape[0], img_square.shape[1])\n",
        "                    square_img = np.zeros((actual_size, actual_size, 3), dtype=np.uint8)\n",
        "                    y_offset = (actual_size - img_square.shape[0]) // 2\n",
        "                    x_offset = (actual_size - img_square.shape[1]) // 2\n",
        "                    square_img[y_offset:y_offset+img_square.shape[0],\n",
        "                             x_offset:x_offset+img_square.shape[1]] = img_square\n",
        "\n",
        "                    # 切り抜き画像の保存\n",
        "                    output_image_path = os.path.join(out_images_dir, f\"{output_filename}.png\")\n",
        "                    cv2.imwrite(output_image_path, square_img)\n",
        "\n",
        "                    # マスク画像を生成（ラベルとボックスなし）\n",
        "                    mask_img = results[0].plot(labels=False, boxes=False)\n",
        "\n",
        "                    # マスク画像も同じ正方形領域で切り出し\n",
        "                    mask_square = mask_img[square_y1:square_y2, square_x1:square_x2]\n",
        "\n",
        "                    # マスク画像も同様にパディング処理\n",
        "                    square_mask = np.zeros((actual_size, actual_size, 3), dtype=np.uint8)\n",
        "                    square_mask[y_offset:y_offset+mask_square.shape[0],\n",
        "                              x_offset:x_offset+mask_square.shape[1]] = mask_square\n",
        "\n",
        "                    # マスク画像の保存\n",
        "                    cv2.imwrite(os.path.join(out_masks_dir, f\"{output_filename}_mask.png\"), square_mask)\n",
        "\n",
        "                # YOLOのラベルを記載したtextファイルを作成\n",
        "                label_path = os.path.join(out_labels_dir, f\"{output_filename}.txt\")\n",
        "                with open(label_path, \"w\") as f:\n",
        "                    # Haarcascadeで検出された目の座標をすべて書き込み\n",
        "                    for i, (haar_eye_x, haar_eye_y, haar_eye_w, haar_eye_h) in enumerate(eye_list):\n",
        "                        eye_label = i  # 0: 右目, 1: 左目\n",
        "                        # もとの画像に対する相対座標を計算\n",
        "                        yolo_x = (haar_eye_x + haar_eye_w/2) / img.shape[1]  # 中心のx座標\n",
        "                        yolo_y = (haar_eye_y + haar_eye_h/2) / img.shape[0]  # 中心のy座標\n",
        "                        yolo_w = haar_eye_w / img.shape[1]  # 幅\n",
        "                        yolo_h = haar_eye_h / img.shape[0]  # 高さ\n",
        "\n",
        "                        # Haarcascadeの検出結果を書き込み\n",
        "                        f.write(f\"{eye_label} {yolo_x:.6f} {yolo_y:.6f} {yolo_w:.6f} {yolo_h:.6f}\\n\")\n",
        "\n",
        "                    # YOLOv11の検出結果からeyelidの横幅を取得\n",
        "                    eyelid_box = None\n",
        "                    for result in results:\n",
        "                        boxes = result.boxes\n",
        "                        for box in boxes:\n",
        "                            cls_id = int(box.cls)\n",
        "                            if cls_id == 0:  # eyelidのクラスID = 0\n",
        "                                yolo_x1, yolo_y1, yolo_x2, yolo_y2 = box.xyxy[0]  # xyxy形式で座標を取得\n",
        "                                yolo_width = yolo_x2 - yolo_x1  # 実際のピクセル幅\n",
        "                                if eyelid_box is None or yolo_width > eyelid_box[2]:\n",
        "                                    eyelid_box = (yolo_x1, yolo_y1, yolo_width, yolo_y2 - yolo_y1)\n",
        "\n",
        "                    if eyelid_box is not None:\n",
        "                        yolo_x1, yolo_y1, yolo_width, yolo_height = eyelid_box\n",
        "                        # eyelidの横幅を基準に正方形サイズを計算\n",
        "                        square_size = yolo_width * 1.5  # padding 25% × 2 = 50% 増\n",
        "\n",
        "                        # YOLOv11の検出結果を正方形サイズで正規化\n",
        "                        for result in results:\n",
        "                            boxes = result.boxes\n",
        "                            for box in boxes:\n",
        "                                cls_id = int(box.cls)\n",
        "                                yolo_box_x1, yolo_box_y1, yolo_box_x2, yolo_box_y2 = box.xyxy[0]  # xyxy形式で座標を取得\n",
        "\n",
        "                                # 中心座標とサイズを計算（正方形の中心を基準に）\n",
        "                                center_x = (yolo_box_x1 + yolo_box_x2) / 2\n",
        "                                center_y = (yolo_box_y1 + yolo_box_y2) / 2\n",
        "                                box_w = yolo_box_x2 - yolo_box_x1\n",
        "                                box_h = yolo_box_y2 - yolo_box_y1\n",
        "\n",
        "                                # eyelidの中心を正方形の中心（0.5, 0.5）とした相対座標に変換\n",
        "                                relative_x = 0.5 + ((center_x - (yolo_x1 + yolo_width/2)) / square_size)\n",
        "                                relative_y = 0.5 + ((center_y - (yolo_y1 + yolo_height/2)) / square_size)\n",
        "                                relative_w = box_w / square_size\n",
        "                                relative_h = box_h / square_size\n",
        "\n",
        "                                # YOLOv11の検出結果を追記\n",
        "                                f.write(f\"{cls_id} {relative_x:.6f} {relative_y:.6f} {relative_w:.6f} {relative_h:.6f}\\n\")\n",
        "                    else:\n",
        "                        print(f\"Warning: No eyelid detected in {output_filename}\")\n",
        "            else:\n",
        "                print(f\"画像 {id}: Invalid crop coordinates. Skipping.\")\n",
        "    else:\n",
        "        print(f\"画像 {id}: {len(eye_list)}個の目が検出されたため、スキップします。\")"
      ],
      "metadata": {
        "id": "IZ35pu8_iREZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**mask --> points**"
      ],
      "metadata": {
        "id": "3KoUyVqkd_8r"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RhMA6ATFDLla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MW9xX0Rw8E9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y7uKQ9gqco03"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}