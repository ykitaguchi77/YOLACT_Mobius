{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMfM8RJojxvcgMVZ7tuP/w+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/YOLACT_Mobius/blob/main/YOLOv%EF%BC%98_dataset_preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Mobius_dataset --> YOLOv8 instance segmentation training**\n",
        "\n",
        "2024ç ”ç©¶å®¤é…å±ï¼ˆéˆ´æœ¨ãã‚“ã€åŒ—å£ãã‚“ï¼‰\n",
        "\n",
        "```\n",
        "To doï¼š\n",
        "\n",
        "Mobiusã®ãƒã‚¹ã‚¯ç”»åƒã‚’YOLOv8å½¢å¼ã®ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã«\n",
        "\n",
        "ãƒã‚¹ã‚¯ç”»åƒãŒãªã„ç”»åƒã‚’é™¤å¤–\n",
        "\n",
        "YOLOv8ç”¨ã®ãƒ•ã‚©ãƒ«ãƒ€æ§‹æˆã«\n",
        "```"
      ],
      "metadata": {
        "id": "UO-YiNInXIqU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqgoOYBDXINA",
        "outputId": "3ef0c9e8-e4e8-41c3-a2f4-aeb98a7f9751"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**COCO_jsonå½¢å¼ã¸ã®å¤‰æ›**"
      ],
      "metadata": {
        "id": "KyVVyl1QgCtQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import json\n",
        "from skimage import measure\n",
        "import os\n",
        "from google.colab import drive\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ç”»åƒã‹ã‚‰ç‰¹å®šã®è‰²ã®ãƒã‚¹ã‚¯ã‚’ä½œæˆã™ã‚‹\n",
        "def create_mask(image, color):\n",
        "    return np.all(image == color, axis=-1)\n",
        "\n",
        "# ãƒã‚¹ã‚¯ã‚’é©ç”¨ã—ã¦ç”»åƒã‚’å¤‰æ›ã™ã‚‹\n",
        "def apply_mask(image, mask):\n",
        "    return np.where(mask, 255, 0)\n",
        "\n",
        "# ç”»åƒã‹ã‚‰è¼ªéƒ­ã‚’æŠ½å‡ºã—ã€ç‚¹ã®ãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹\n",
        "def extract_contours(img, _num_points):\n",
        "    contours = measure.find_contours(img, 0.5)\n",
        "    points_list = []\n",
        "\n",
        "    for contour in contours:\n",
        "        contour_length = len(contour)\n",
        "\n",
        "        if contour_length > _num_points:\n",
        "            step = contour_length // _num_points\n",
        "            selected_points = [contour[i * step] for i in range(_num_points)]\n",
        "        else:\n",
        "            selected_points = contour\n",
        "\n",
        "        points = [[float(point[1]), float(point[0])] for point in selected_points]\n",
        "        points_list.append(points)\n",
        "\n",
        "    return points_list\n",
        "\n",
        "# ç‚¹ã®ãƒªã‚¹ãƒˆã‹ã‚‰JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã™ã‚‹\n",
        "def create_json(points_list_blue, points_list_blue_green, points_list_all_colors, json_name, img_path, img_data, img_height, img_width):\n",
        "    data = {\n",
        "        \"version\": \"5.4.1\",\n",
        "        \"flags\": {},\n",
        "        \"shapes\": [],\n",
        "        \"imagePath\": img_path,\n",
        "        \"imageData\": img_data,\n",
        "        \"imageHeight\": img_height,\n",
        "        \"imageWidth\": img_width\n",
        "    }\n",
        "\n",
        "    # ç‚¹ã®ãƒ‡ãƒ¼ã‚¿ã‚’JSONæ§‹é€ ã«è¿½åŠ \n",
        "    data[\"shapes\"].append({\n",
        "        \"label\": \"eyelid\",\n",
        "        \"points\": points_list_all_colors,\n",
        "        \"group_id\": None,\n",
        "        \"description\": \"\",\n",
        "        \"shape_type\": \"polygon\",\n",
        "        \"flags\": {},\n",
        "        \"mask\": None\n",
        "    })\n",
        "\n",
        "    data[\"shapes\"].append({\n",
        "        \"label\": \"iris\",\n",
        "        \"points\": points_list_blue_green,\n",
        "        \"group_id\": None,\n",
        "        \"description\": \"\",\n",
        "        \"shape_type\": \"polygon\",\n",
        "        \"flags\": {},\n",
        "        \"mask\": None\n",
        "    })\n",
        "\n",
        "    data[\"shapes\"].append({\n",
        "        \"label\": \"pupil\",\n",
        "        \"points\": points_list_blue,\n",
        "        \"group_id\": None,\n",
        "        \"description\": \"\",\n",
        "        \"shape_type\": \"polygon\",\n",
        "        \"flags\": {},\n",
        "        \"mask\": None\n",
        "    })\n",
        "\n",
        "    with open(json_name, 'w') as fw:\n",
        "        json.dump(data, fw, indent=2)\n",
        "\n",
        "# ç”»åƒã‹ã‚‰ãƒã‚¹ã‚¯ã‚’ä½œæˆã—ã€è¼ªéƒ­ã‚’æŠ½å‡ºã—ã¦JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹\n",
        "def process_single_image(mask_file, json_name):\n",
        "    img = cv2.imread(mask_file, cv2.IMREAD_COLOR)\n",
        "    img_height, img_width = img.shape[:2]\n",
        "\n",
        "    mask_blue = create_mask(img, [255, 0, 0])\n",
        "    mask_green = create_mask(img, [0, 255, 0])\n",
        "    mask_red = create_mask(img, [0, 0, 255])\n",
        "\n",
        "    mask_blue_green = np.logical_or(mask_blue, mask_green)\n",
        "    mask_all_colors = np.logical_or(mask_blue_green, mask_red)\n",
        "\n",
        "    img_blue = apply_mask(img, mask_blue)\n",
        "    img_blue_green = apply_mask(img, mask_blue_green)\n",
        "    img_all_colors = apply_mask(img, mask_all_colors)\n",
        "\n",
        "    points_list_blue = extract_contours(img_blue, num_points)\n",
        "    points_list_blue_green = extract_contours(img_blue_green, num_points)\n",
        "    points_list_all_colors = extract_contours(img_all_colors, num_points)\n",
        "\n",
        "    create_json(points_list_blue, points_list_blue_green, points_list_all_colors, json_name, mask_file, \"/9\", img_height, img_width)\n",
        "\n",
        "# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨ç”»åƒã«å¯¾ã—ã¦ä¸Šè¨˜ã®å‡¦ç†ã‚’ã¾ã¨ã‚ã¦è¡Œã†\n",
        "def process_images(mask_dir, output_json_dir, num_images=10):\n",
        "    if not os.path.exists(mask_dir):\n",
        "        raise FileNotFoundError(f\"The directory {mask_dir} does not exist.\")\n",
        "\n",
        "    if not os.path.exists(output_json_dir):\n",
        "        user_input = input(f\"The directory {output_json_dir} does not exist. Do you want to create it? (y/n): \")\n",
        "        if user_input.lower() == 'y':\n",
        "            os.makedirs(output_json_dir)\n",
        "            print(f\"Created directory {output_json_dir}\")\n",
        "        else:\n",
        "            print(\"Directory not created. Exiting the process.\")\n",
        "            return\n",
        "\n",
        "    total_images = sum([len(files) for r, d, files in os.walk(mask_dir) if files])\n",
        "\n",
        "    with tqdm(total=min(total_images, num_images)) as pbar:\n",
        "        for folder in os.listdir(mask_dir):\n",
        "            folder_path = os.path.join(mask_dir, folder)\n",
        "            if not os.path.isdir(folder_path):\n",
        "                continue\n",
        "\n",
        "            output_folder = os.path.join(output_json_dir, folder)\n",
        "            os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "            for filename in os.listdir(folder_path):\n",
        "                if filename.endswith(\".png\"):\n",
        "                    mask_file = os.path.join(folder_path, filename)\n",
        "                    json_name = os.path.join(output_folder, filename.replace(\".png\", \".json\"))\n",
        "\n",
        "                    process_single_image(mask_file, json_name)\n",
        "\n",
        "                    pbar.update(1)\n",
        "                    if pbar.n >= num_images:\n",
        "                        return\n",
        "\n"
      ],
      "metadata": {
        "id": "FJ82CD49EZuI"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ãƒã‚¹ã‚¯ã•ã‚ŒãŸç”»åƒã®ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚\n",
        "mask_file = \"/content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/Sample_Mobius_dataset/masks/1/1_1i_Ll_1.png\"\n",
        "json_name = \"/content/output.json\"\n",
        "\n",
        "#è¼ªéƒ­ç‚¹ã®å€‹æ•°ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚\n",
        "num_points = 24\n",
        "\n",
        "process_single_image(mask_file, json_name)\n",
        "\n",
        "# å…ƒç”»åƒã¨è¼ªéƒ­ã®æ¯”è¼ƒ\n",
        "matplotlib.rcParams['axes.unicode_minus'] = False\n",
        "with open('/content/output.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "points_eyelid = []\n",
        "points_iris = []\n",
        "points_pupil = []\n",
        "for shape in data['shapes']:\n",
        "    if shape['label'] == 'eyelid':\n",
        "        points_eyelid += shape['points'][0]\n",
        "    elif shape['label'] == 'iris':\n",
        "        points_iris += shape['points'][0]\n",
        "    elif shape['label'] == 'pupil':\n",
        "        points_pupil += shape['points'][0]\n",
        "\n",
        "\n",
        "x_eyelid = [point[0] for point in points_eyelid]\n",
        "y_eyelid = [point[1] for point in points_eyelid]\n",
        "\n",
        "x_iris = [point[0] for point in points_iris]\n",
        "y_iris = [point[1] for point in points_iris]\n",
        "\n",
        "x_pupil = [point[0] for point in points_pupil]\n",
        "y_pupil = [point[1] for point in points_pupil]\n",
        "\n",
        "# å…ƒã®ç”»åƒã‚’èª­ã¿è¾¼ã‚€\n",
        "img_path = \"/content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/Sample_Mobius_dataset/images/1/1_1i_Ll_1.jpg\"\n",
        "img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "\n",
        "# å›³ã®å·¦éš£ã«å…ƒã®ç”»åƒã‚’è¡¨ç¤ºã™ã‚‹\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(img_rgb)\n",
        "plt.title(\"original\")\n",
        "\n",
        "# å›³ã®å³éš£ã«æ•£å¸ƒå›³ã‚’è¡¨ç¤ºã™ã‚‹\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.scatter(x_eyelid, y_eyelid, label='eyelid')\n",
        "plt.scatter(x_iris, y_iris, label='iris')\n",
        "plt.scatter(x_pupil, y_pupil, label='pupil')\n",
        "plt.title(\"contour\")#è¼ªéƒ­\n",
        "\n",
        "# ç¸¦æ¨ªã®ç¸®å°ºã‚’åŒã˜ã«ã™ã‚‹\n",
        "plt.axis('equal')\n",
        "\n",
        "# ç¸¦è»¸ã‚’é™é †ã«ã™ã‚‹\n",
        "plt.gca().invert_yaxis()\n",
        "\n",
        "# å‡¡ä¾‹ã‚’è¡¨ç¤ºã™ã‚‹\n",
        "plt.legend()\n",
        "\n",
        "# å›³ã‚’è¡¨ç¤ºã™ã‚‹\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrryMPq_aYmb",
        "outputId": "796c583c-484f-4191-c83c-4802c75bbf93"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-e6a460a0f4bc>:43: MatplotlibDeprecationWarning: Auto-removal of overlapping axes is deprecated since 3.6 and will be removed two minor releases later; explicitly call ax.remove() as needed.\n",
            "  plt.subplot(1, 2, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# åŸºæœ¬ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š\n",
        "mask_dir = \"/content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/Sample_Mobius_dataset/masks\"\n",
        "output_json_dir = \"/content/output_json\""
      ],
      "metadata": {
        "id": "4Ps2mN9fYgFc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# æœ€åˆã¯10æšã®ç”»åƒã§ãƒ†ã‚¹ãƒˆ\n",
        "process_images(mask_dir, output_json_dir, num_images=10)\n",
        "\n",
        "# å•é¡ŒãŒãªã‘ã‚Œã°å…¨ç”»åƒã«é©ç”¨\n",
        "# process_images(base_dir, output_dir, num_images=float('inf'))"
      ],
      "metadata": {
        "id": "UOYhHI09YkwO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e40e5ba-e21c-4773-fc56-884e084e3f63"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The directory /content/output_json does not exist. Do you want to create it? (y/n): y\n",
            "Created directory /content/output_json\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:08<00:00,  1.12it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "def process_all_json_files(json_dir, num_images=10):\n",
        "    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ç·æ•°ã‚’å–å¾—\n",
        "    total_files = sum([len(files) for r, d, files in os.walk(json_dir) if files])\n",
        "\n",
        "    # tqdmã‚’ä½¿ã£ã¦é€²æ—ãƒãƒ¼ã‚’åˆæœŸåŒ–\n",
        "    with tqdm(total=min(total_files, num_images)) as pbar:\n",
        "        for root, dirs, files in os.walk(json_dir):\n",
        "            for file in files:\n",
        "                if file.endswith(\".json\"):\n",
        "                    json_file_path = os.path.join(root, file)\n",
        "\n",
        "                    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿\n",
        "                    with open(json_file_path, 'r') as json_file:\n",
        "                        data = json.load(json_file)\n",
        "\n",
        "                    # imagePathã®å€¤ã‚’ãƒ•ã‚¡ã‚¤ãƒ«åã®ã¿ã«æ›´æ–°\n",
        "                    data[\"imagePath\"] = os.path.basename(data[\"imagePath\"])\n",
        "\n",
        "                    # JSONãƒ•ã‚¡ã‚¤ãƒ«ã«å¤‰æ›´ã‚’ä¿å­˜\n",
        "                    with open(json_file_path, 'w') as json_file:\n",
        "                        json.dump(data, json_file, indent=4)\n",
        "\n",
        "                    pbar.update(1)  # é€²æ—ãƒãƒ¼ã‚’æ›´æ–°\n",
        "                    if pbar.n >= num_images:\n",
        "                        return  # æŒ‡å®šã•ã‚ŒãŸæ•°ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ãŸã‚‰çµ‚äº†\n",
        "\n",
        "# JSONãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹\n",
        "json_dir = \"/content/output_json\"\n",
        "\n",
        "# æœ€åˆã¯10å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒ†ã‚¹ãƒˆ\n",
        "process_all_json_files(json_dir, num_images=10)\n",
        "\n",
        "# å•é¡ŒãŒãªã‘ã‚Œã°ã€å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã«é©ç”¨\n",
        "#process_all_json_files(json_dir, num_images=float('inf'))\n"
      ],
      "metadata": {
        "id": "j5n3-ew1YoeG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed980a33-8a5c-43c9-ec01-bfbaefcc5aac"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 1339.99it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # prompt: jsonãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚©ãƒ«ãƒ€ã«å…¥ã£ã¦ã„ã‚‹å…¨ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ©ãƒãƒ©ã®çŠ¶æ…‹ã§ä¸€ã¤ä¸€ã¤ã€/content/drive/MyDrive/AI_laboratory_course/MOBIUS/json_concatã«ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã¦ãã ã•ã„\n",
        "\n",
        "# import os\n",
        "# import shutil\n",
        "\n",
        "# source_dir = \"/content/output_json\"\n",
        "# target_dir = \"/content/concat_json\"\n",
        "\n",
        "# # Create the directory if it doesn't exist\n",
        "# if not os.path.exists(target_dir):\n",
        "#     os.makedirs(target_dir)\n",
        "#     print(f\"Directory '{target_dir}' was created.\")\n",
        "\n",
        "\n",
        "# for folder in os.listdir(source_dir):\n",
        "#     folder_path = os.path.join(source_dir, folder)\n",
        "#     print(folder_path)\n",
        "#     if os.path.isdir(folder_path):\n",
        "#         for file in os.listdir(folder_path):\n",
        "#             file_path = os.path.join(folder_path, file)\n",
        "#             print(file_path)\n",
        "#             shutil.copy(file_path, target_dir)"
      ],
      "metadata": {
        "id": "M_GmoOhbb-vY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# !pip install labelme2coco\n",
        "# import labelme2coco\n",
        "\n",
        "# # LabelMeã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¨ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒå«ã¾ã‚Œã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š\n",
        "# labelme_folder = \"/content/drive/MyDrive/AI_laboratory_course/MOBIUS/concat_json\"\n",
        "\n",
        "# # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š\n",
        "# export_dir = \"/content/drive/MyDrive/AI_laboratory_course/MOBIUS/coco_format\"\n",
        "\n",
        "# # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²ç‡ã‚’è¨­å®š\n",
        "# train_split_rate = 0.85\n",
        "\n",
        "# # LabelMeã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’COCOå½¢å¼ã«å¤‰æ›\n",
        "# labelme2coco.convert(labelme_folder, export_dir, train_split_rate)"
      ],
      "metadata": {
        "id": "HPR155zyca9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ãƒã‚¹ãƒˆã‚’æ¸›ã‚‰ã™ã‚³ãƒ¼ãƒ‰ (è¦ä¿®æ­£)"
      ],
      "metadata": {
        "id": "0cNyhbXsd4VD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "def convert_points_format(json_file_path):\n",
        "    with open(json_file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    for shape in data['shapes']:\n",
        "        # ãƒã‚¹ãƒˆã‚’1ãƒ¬ãƒ™ãƒ«æ¸›ã‚‰ã—ã¾ã™\n",
        "        shape['points'] = [point[0] for point in shape['points']]\n",
        "\n",
        "    with open(json_file_path, 'w') as file:\n",
        "        json.dump(data, file, indent=4)\n",
        "\n",
        "# JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒä¿å­˜ã•ã‚Œã¦ã„ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¸ã®ãƒ‘ã‚¹\n",
        "json_dir = \"/content/concat_json\"\n",
        "\n",
        "# JSONãƒ•ã‚¡ã‚¤ãƒ«ã®ç·æ•°ã‚’å–å¾—\n",
        "total_files = sum([len(files) for r, d, files in os.walk(json_dir) if files])\n",
        "\n",
        "# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨ã¦ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦ä¸Šè¨˜ã®é–¢æ•°ã‚’é©ç”¨ï¼ˆtqdmã‚’ä½¿ç”¨ï¼‰\n",
        "with tqdm(total=total_files, desc=\"Converting JSON files\") as pbar:\n",
        "    for root, dirs, files in os.walk(json_dir):\n",
        "        for file in files:\n",
        "            if file.endswith(\".json\"):\n",
        "                json_file_path = os.path.join(root, file)\n",
        "                convert_points_format(json_file_path)\n",
        "                pbar.update(1)"
      ],
      "metadata": {
        "id": "6bt34wEeckLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5fe0874-4b14-4055-98e0-5f4a7cec59f7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting JSON files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 1257.32it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install labelme2coco\n",
        "import labelme2coco\n",
        "\n",
        "# LabelMeã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¨ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒå«ã¾ã‚Œã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š\n",
        "labelme_folder = \"/content/drive/MyDrive/AI_laboratory_course/MOBIUS/ex_json\"\n",
        "\n",
        "# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š\n",
        "export_dir = \"/content/drive/MyDrive/AI_laboratory_course/MOBIUS/coco_format\"\n",
        "\n",
        "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²ç‡ã‚’è¨­å®š\n",
        "train_split_rate = 0.85\n",
        "\n",
        "# LabelMeã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’COCOå½¢å¼ã«å¤‰æ›\n",
        "labelme2coco.convert(labelme_folder, export_dir, train_split_rate)"
      ],
      "metadata": {
        "id": "7o4cleqje5-W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LabelMeã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¨ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒå«ã¾ã‚Œã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š\n",
        "labelme_folder = \"/content/drive/MyDrive/AI_laboratory_course/MOBIUS/concat_json\"\n",
        "\n",
        "# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®š\n",
        "export_dir = \"/content/drive/MyDrive/AI_laboratory_course/MOBIUS/coco_format\"\n",
        "\n",
        "# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²ç‡ã‚’è¨­å®š\n",
        "train_split_rate = 0.85\n",
        "\n",
        "# ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ãƒˆã‚’å–å¾—\n",
        "file_list = os.listdir(labelme_folder)\n",
        "\n",
        "# é€²æ—ãƒãƒ¼ã‚’è¡¨ç¤ºã—ã¦LabelMeã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã‚’COCOå½¢å¼ã«å¤‰æ›\n",
        "for file_name in tqdm(file_list, desc=\"Converting to COCO\"):\n",
        "    if file_name.endswith('.json'):\n",
        "        json_file_path = os.path.join(labelme_folder, file_name)\n",
        "        labelme2coco.convert(json_file_path, export_dir, train_split_rate)\n",
        "\n",
        "print(\"Conversion complete.\")"
      ],
      "metadata": {
        "id": "ltTxIjdtfCr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**YOLOv8å½¢å¼ã®ã‚¢ãƒãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã¸ã®å¤‰æ›**"
      ],
      "metadata": {
        "id": "MuqoZneUf9Bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage import measure\n",
        "import os\n",
        "from google.colab import drive\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def create_mask(image, color):\n",
        "    return np.all(image == color, axis=-1)\n",
        "\n",
        "def apply_mask(image, mask):\n",
        "    return np.where(mask, 255, 0)\n",
        "\n",
        "def extract_contours(img, _num_points):\n",
        "    contours = measure.find_contours(img, 0.5)\n",
        "    points_list = []\n",
        "\n",
        "    for contour in contours:\n",
        "        contour_length = len(contour)\n",
        "\n",
        "        if contour_length > _num_points:\n",
        "            step = contour_length // _num_points\n",
        "            selected_points = [contour[i * step] for i in range(_num_points)]\n",
        "        else:\n",
        "            selected_points = contour\n",
        "\n",
        "        points = [[float(point[1]), float(point[0])] for point in selected_points]\n",
        "        points_list.append(points)\n",
        "\n",
        "    return points_list\n",
        "\n",
        "def normalize_coordinates(points_list, img_width, img_height):\n",
        "    normalized_points_list = []\n",
        "    for points in points_list:\n",
        "        normalized_points = [[x / img_width, y / img_height] for x, y in points]\n",
        "        normalized_points_list.append(normalized_points)\n",
        "    return normalized_points_list\n",
        "\n",
        "def write_yolov8_annotation(points_list, class_index, img_width, img_height, file):\n",
        "    for points in points_list:\n",
        "        normalized_points = normalize_coordinates([points], img_width, img_height)[0]\n",
        "        line = f\"{class_index} \" + \" \".join(f\"{x} {y}\" for x, y in normalized_points) + \"\\n\"\n",
        "        file.write(line)\n",
        "\n",
        "def create_yolov8_text(mask_file, yolov8_annotation_file, num_points):\n",
        "    img = cv2.imread(mask_file, cv2.IMREAD_COLOR)\n",
        "    img_height, img_width = img.shape[:2]\n",
        "\n",
        "    mask_blue = create_mask(img, [255, 0, 0])\n",
        "    mask_green = create_mask(img, [0, 255, 0])\n",
        "    mask_red = create_mask(img, [0, 0, 255])\n",
        "\n",
        "    mask_blue_green = np.logical_or(mask_blue, mask_green)\n",
        "    mask_all_colors = np.logical_or(mask_blue_green, mask_red)\n",
        "\n",
        "    img_blue = apply_mask(img, mask_blue)\n",
        "    img_blue_green = apply_mask(img, mask_blue_green)\n",
        "    img_all_colors = apply_mask(img, mask_all_colors)\n",
        "\n",
        "    points_list_blue = extract_contours(img_blue, num_points)\n",
        "    points_list_blue_green = extract_contours(img_blue_green, num_points)\n",
        "    points_list_all_colors = extract_contours(img_all_colors, num_points)\n",
        "\n",
        "    with open(yolov8_annotation_file, 'w') as file:\n",
        "        # ã‚¯ãƒ©ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 0: ç¼\n",
        "        write_yolov8_annotation(points_list_blue, 0, img_width, img_height, file)\n",
        "        # ã‚¯ãƒ©ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 1: è™¹å½©\n",
        "        write_yolov8_annotation(points_list_blue_green, 1, img_width, img_height, file)\n",
        "        # ã‚¯ãƒ©ã‚¹ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 2: ç³\n",
        "        write_yolov8_annotation(points_list_all_colors, 2, img_width, img_height, file)\n",
        "\n",
        "mask_file = \"/content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/Sample_Mobius_dataset/masks/1/1_1i_Ll_2.png\"\n",
        "yolov8_annotation_file = \"/content/yolov8_annotation.txt\"\n",
        "num_points = 24\n",
        "\n",
        "create_yolov8_text(mask_file, yolov8_annotation_file, num_points)\n"
      ],
      "metadata": {
        "id": "mMMfQUGeb4-S"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ç¢ºèªï¼ˆimgã¸ã®é‡ã­åˆã‚ã›ï¼‰\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "def read_yolov8_annotation(file_path, img_width, img_height):\n",
        "    annotations = []\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            parts = line.strip().split()\n",
        "            class_index = int(parts[0])\n",
        "            points = [(float(parts[i]), float(parts[i + 1])) for i in range(1, len(parts), 2)]\n",
        "            # æ­£è¦åŒ–è§£é™¤\n",
        "            points = [(x * img_width, y * img_height) for x, y in points]\n",
        "            annotations.append((class_index, points))\n",
        "    return annotations\n",
        "\n",
        "def plot_annotations(img, annotations):\n",
        "    plt.imshow(img)\n",
        "    for class_index, points in annotations:\n",
        "        xs, ys = zip(*points)\n",
        "        plt.plot(xs, ys, marker='o', markersize=2, linestyle='-')\n",
        "\n",
        "    plt.title(\"YOLOv8 Annotations\")\n",
        "    plt.show()\n",
        "\n",
        "# YOLOv8 ã‚¢ãƒãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹\n",
        "yolov8_annotation_file = \"/content/yolov8_annotation.txt\"\n",
        "\n",
        "# å…ƒã®ç”»åƒã®ãƒ‘ã‚¹\n",
        "img_path = \"/content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/Sample_Mobius_dataset/images/1/1_1i_Ll_2.jpg\"\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "img_height, img_width = img.shape[:2]\n",
        "\n",
        "# ã‚¢ãƒãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ã®èª­ã¿è¾¼ã¿ã¨ãƒ—ãƒ­ãƒƒãƒˆ\n",
        "annotations = read_yolov8_annotation(yolov8_annotation_file, img_width, img_height)\n",
        "plot_annotations(img, annotations)\n"
      ],
      "metadata": {
        "id": "9nvecdzgfnbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qCb9EaLOeZEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "\n",
        "images_dir = \"/content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/Sample_Mobius_dataset/images/1\"\n",
        "masks_dir = \"/content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/Sample_Mobius_dataset/masks/1\"\n",
        "output_text_dir = \"/content/yolo8_annotation/\"\n",
        "num_points = 24\n",
        "\n",
        "if os.path.exists(output_text_dir):\n",
        "    shutil.rmtree(output_text_dir)\n",
        "os.makedirs(output_text_dir)\n",
        "\n",
        "filename_list = [os.path.splitext(f)[0] for f in os.listdir(images_dir) if os.path.isfile(os.path.join(images_dir, f))]\n",
        "\n",
        "for img in glob.glob(f\"{images_dir}/*\")[0:5]:\n",
        "    if os.path.splitext(os.path.basename(img))[0] in filename_list:\n",
        "        print(f\"processing... {os.path.splitext(os.path.basename(img))[0]}\")\n",
        "        txt_name = f\"{output_text_dir}/{os.path.splitext(os.path.basename(img))[0]}.txt\"\n",
        "        img = f\"{masks_dir}/{os.path.splitext(os.path.basename(img))[0]}.png\"\n",
        "        create_yolov8_text(img, txt_name, num_points)\n",
        "    else:\n",
        "        print(\"false\")"
      ],
      "metadata": {
        "id": "aoRJ4HLEj2zA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "995b96b6-ad85-4b7b-ec17-91a3bcc37fc6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processing... 1_1i_Ll_2\n",
            "processing... 1_1i_Ll_1\n",
            "processing... 1_1i_Lr_1\n",
            "processing... 1_1i_Ls_1\n",
            "processing... 1_1i_Lr_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# å¯¾å¿œã™ã‚‹ãƒã‚¹ã‚¯ç”»åƒã‚’ä½¿ç”¨ã—ã¦YOLOv8ç”¨ã®ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¾ã™ã€‚\n",
        "# images_dirã®å„ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª(/1, /2ãªã©)ã«å¯¾ã—ã¦ã€åŒã˜å‡¦ç†ã‚’é©ç”¨ã—ã¾ã™ã€‚\n",
        "# åŒæ§˜ã«ã€masks_dirã®ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰ãƒã‚¹ã‚¯ç”»åƒã‚’å–å¾—ã—ã€\n",
        "# å‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’output_text_dirã®åŒã˜ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã«ä¿å­˜ã—ã¾ã™ã€‚\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "\n",
        "images_dir = \"/content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/Sample_Mobius_dataset/images\"\n",
        "masks_dir = \"/content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/Sample_Mobius_dataset/masks\"\n",
        "output_text_dir = \"/content/yolo8_annotation/\"\n",
        "num_points = 24\n",
        "\n",
        "# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®åˆæœŸåŒ–\n",
        "if os.path.exists(output_text_dir):\n",
        "    shutil.rmtree(output_text_dir)\n",
        "os.makedirs(output_text_dir)\n",
        "\n",
        "# images_dirã®ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’èµ°æŸ»\n",
        "for subdir in os.listdir(images_dir):\n",
        "    images_subdir = os.path.join(images_dir, subdir)\n",
        "    masks_subdir = os.path.join(masks_dir, subdir)\n",
        "    output_subdir = os.path.join(output_text_dir, subdir)\n",
        "\n",
        "    if os.path.isdir(images_subdir) and os.path.isdir(masks_subdir):\n",
        "        os.makedirs(output_subdir, exist_ok=True)\n",
        "\n",
        "        # ãƒ•ã‚¡ã‚¤ãƒ«åãƒªã‚¹ãƒˆã‚’å–å¾—\n",
        "        filename_list = [os.path.splitext(f)[0] for f in os.listdir(images_subdir) if os.path.isfile(os.path.join(images_subdir, f))]\n",
        "\n",
        "        #for img_path in glob.glob(f\"{images_subdir}/*\"):\n",
        "        for img_path in glob.glob(f\"{images_subdir}/*\")[0:5]:\n",
        "            base_name = os.path.splitext(os.path.basename(img_path))[0]\n",
        "\n",
        "            if base_name in filename_list:\n",
        "                print(f\"processing... {base_name}\")\n",
        "                txt_name = os.path.join(output_subdir, f\"{base_name}.txt\")\n",
        "                mask_img_path = os.path.join(masks_subdir, f\"{base_name}.png\")\n",
        "                create_yolov8_text(mask_img_path, txt_name, num_points)\n",
        "            else:\n",
        "                print(\"false\")\n"
      ],
      "metadata": {
        "id": "8ceK1D6-Knvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #################\n",
        "# # åŒ—å£ãã‚“ã®å¤‰æ›ã‚³ãƒ¼ãƒ‰ #\n",
        "# #################\n",
        "# from time import monotonic#å¤šåˆ†ã„ã‚‰ãªã„\n",
        "# #æœ¬ä½“ã¯ä»¥ä¸‹ã‹ã‚‰\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "# #driveã®ãƒã‚¦ãƒ³ãƒˆ\n",
        "\n",
        "# import os\n",
        "# import json\n",
        "# import numpy as np\n",
        "\n",
        "# # jsonãƒ•ã‚¡ã‚¤ãƒ«ã®å…¥ã£ã¦ã„ã‚‹ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ã‚’æŒ‡å®š\n",
        "# folder_path = '/content/drive/MyDrive/json-20240205T053811Z-001/json/4'\n",
        "\n",
        "\n",
        "\n",
        "# # ãƒ•ã‚©ãƒ«ãƒ€å†…ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚¢ã‚¯ã‚»ã‚¹\n",
        "# for filename in os.listdir(folder_path):\n",
        "#     file_path = os.path.join(folder_path, filename)\n",
        "\n",
        "#     # ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã©ã†ã‹ã‚’ç¢ºèª\n",
        "#     if os.path.isfile(file_path):\n",
        "#         # ã“ã“ã§ãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã™ã‚‹å‡¦ç†ã‚’è¡Œã„ã¾ã™\n",
        "#         print(f'ãƒ•ã‚¡ã‚¤ãƒ«å: {filename}, ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹: {file_path}')\n",
        "\n",
        "\n",
        "#         with open(file_path,'r') as json_open:\n",
        "\n",
        "#             json_load = json.load(json_open)\n",
        "#             height = json_load['imageHeight']\n",
        "#             width = json_load['imageWidth']\n",
        "#             wh = np.array([width,height]) #å‰²ã‚‹ãŸã‚ã®åˆ†æ¯é…åˆ—\n",
        "#             # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’æ›¸ãè¾¼ã‚€\n",
        "#             txtfile_name = f'{filename[:-5]}.txt'   #æ‹¡å¼µå­(.json)ã‚’å‰Šé™¤\n",
        "#             txtfile_path = os.path.join('/content/drive/MyDrive/textfile_for_v8/4', txtfile_name)  # ãƒ•ã‚¡ã‚¤ãƒ«ã®åå‰ã¨ä¿å­˜å…ˆã®ãƒ‘ã‚¹ã‚’æŒ‡å®š\n",
        "\n",
        "#             for i in range(3):#eyelid,irys,pupilã®ä¸‰å›åˆ†\n",
        "#                 points = [i for sublist in json_load['shapes'][i]['points'] for i in sublist]\n",
        "#                 pointsnp = np.array(points)\n",
        "#                 res = pointsnp/wh\n",
        "#                 monores = [element for row in res for element in row]#æ¬¡å…ƒä¸‹ã’\n",
        "\n",
        "#                 line = ' '.join(map(str, monores))\n",
        "\n",
        "\n",
        "#                 text_to_write = f'{i} {line}\\n'  #æ›¸ãå†…å®¹\n",
        "#                 with open(txtfile_path, 'a') as file:\n",
        "\n",
        "#                     file.write(text_to_write)\n",
        "\n",
        "\n",
        "\n",
        "#                 print(f'{file_path} ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¾ã—ãŸã€‚{points} {wh}')#ä¸è¦"
      ],
      "metadata": {
        "id": "DpEJn4jjkhaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**YOLOv8ã®train (éˆ´æœ¨ãã‚“)**\n",
        "\n",
        "ãƒ» badãŒå«ã¾ã‚Œã¦ã„ã‚‹ç”»åƒãŠã‚ˆã³annotationã‚’å‰Šé™¤ã™ã‚‹\n",
        "\n",
        "ãƒ» imagesã®pngã¨annotationã®ãƒ†ã‚­ã‚¹ãƒˆã¨ã‚’åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã«ã—ã¦ã€trainã¨valã«åˆ†ã‘ã‚‹"
      ],
      "metadata": {
        "id": "TLJPf1k1fTCi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#driveã®ãƒã‚¦ãƒ³ãƒˆ"
      ],
      "metadata": {
        "id": "KoAmfvOeK_T-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "807cd824-69e5-4d75-ae4b-42da72a2260a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/ultralytics/ultralytics\n",
        "%cd ultralytics\n",
        "#yolov8"
      ],
      "metadata": {
        "id": "PYuPV9j0fhVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b00e3ae3-3df9-4c56-d33f-7dd3960e48e9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "fatal: destination path 'ultralytics' already exists and is not an empty directory.\n",
            "/content/ultralytics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ç°¡å˜ã«ç¢ºèª"
      ],
      "metadata": {
        "id": "ToMGs5HtTegS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#æœ¬ä½“\n",
        "from ultralytics import YOLO\n",
        "model = YOLO(\"yolov8x.pt\")\n",
        "\n",
        "results = model(\"https://ultralytics.com/images/bus.jpg\",save=True)\n",
        "#Results saved to /content/ultralytics/runs/detect/predictã®ä¸‹ã«ä¿å­˜ã•ã‚Œã‚‹"
      ],
      "metadata": {
        "id": "t_UKew5lfqUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = YOLO(\"yolov8n-seg.pt\")\n",
        "results = model('bus.jpg',save=True,task='segment')#/content/ultralytics/bus.jpgã‚’åˆ©ç”¨\n",
        "#Results saved to /content/ultralytics/runs/segment/predictã®ä¸‹ã«ä¿å­˜ã•ã‚Œã‚‹"
      ],
      "metadata": {
        "id": "vg-GjTEKgew0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Trainig"
      ],
      "metadata": {
        "id": "Cx3FxsuzTh1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#BadãŒå«ã¾ã‚Œã¦ã„ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "directory_list = [\"/content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/sample_dataset_for_YOLOv8/images/train\",\n",
        "                  \"/content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/sample_dataset_for_YOLOv8/images/val\"]\n",
        "\n",
        "# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®ã™ã¹ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¨ãƒ•ã‚©ãƒ«ãƒ€ã‚’ãƒã‚§ãƒƒã‚¯\n",
        "for directory in directory_list:\n",
        "    for item in os.listdir(directory):\n",
        "        # \"bad\"ã¨ã„ã†æ–‡å­—åˆ—ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª\n",
        "        if \"bad\" in item:\n",
        "            path_to_remove = os.path.join(directory, item)\n",
        "\n",
        "            # ãƒ•ã‚¡ã‚¤ãƒ«ã¾ãŸã¯ãƒ•ã‚©ãƒ«ãƒ€ã‚’å‰Šé™¤\n",
        "            if os.path.isfile(path_to_remove):\n",
        "                os.remove(path_to_remove)\n",
        "            elif os.path.isdir(path_to_remove):\n",
        "                shutil.rmtree(path_to_remove)\n",
        "            print(f\"Removed: {path_to_remove}\")"
      ],
      "metadata": {
        "id": "QQaXxExaTbDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# YAMLãƒ•ã‚¡ã‚¤ãƒ«ã®ä½œæˆ\n",
        "\n",
        "%%writefile /content/eyesegmentation.yaml\n",
        "# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n",
        "path: /content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/sample_dataset_for_YOLOv8  # dataset root dir\n",
        "train: images/train  # train images (relative to 'path')\n",
        "val: images/val  # val images (relative to 'path')\n",
        "test: images/val # test images (optional)\n",
        "\n",
        "# Classes\n",
        "names:\n",
        "  0: eyelid\n",
        "  1: iris\n",
        "  2: pupil\n",
        "\n",
        "# Download script/URL (optional)\n",
        "download: https://ultralytics.com/assets/coco128-seg.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSkax_PWK855",
        "outputId": "322ede05-be6e-4f24-a6f4-0e91d9d440c6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/eyesegmentation.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# #æœ¬ä½“\n",
        "# import shutil\n",
        "\n",
        "# # ã‚³ãƒ”ãƒ¼å…ƒãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹\n",
        "# source_file_path = '/content/drive/MyDrive/eyeditect-1.yaml'\n",
        "\n",
        "# # ã‚³ãƒ”ãƒ¼å…ˆãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹\n",
        "# destination_folder = '/content/ultralytics/ultralytics/cfg/datasets'\n",
        "\n",
        "# # shutilãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®copyé–¢æ•°ã‚’ä½¿ç”¨ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼\n",
        "# shutil.copy(source_file_path, destination_folder)"
      ],
      "metadata": {
        "id": "LCpXut8th0y1"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "#æœ¬ä½“\n",
        "#nc = 3ã«å¤‰æ›´\n",
        "# Load a model\n",
        "model = YOLO('yolov8n-seg.yaml').load('yolov8n-seg.pt')  # build from YAML and transfer weights"
      ],
      "metadata": {
        "id": "gE_MJLxNh1po",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe7c85c8-fd33-4267-fdd7-870a6827133f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transferred 417/417 items from pretrained weights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result =  model.train(data='/content/eyesegmentation.yaml', epochs=30, imgsz=640)"
      ],
      "metadata": {
        "id": "2BBtFTuGiJSS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fe1b81d-8702-457b-8cdb-a204a2db90d7"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.20 ğŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8n-seg.yaml, data=/content/eyesegmentation.yaml, epochs=30, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train5, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/ultralytics/runs/segment/train5\n",
            "Overriding model.yaml nc=80 with nc=3\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1   1004665  ultralytics.nn.modules.head.Segment          [3, 32, 64, [64, 128, 256]]   \n",
            "YOLOv8n-seg summary: 261 layers, 3264201 parameters, 3264185 gradients\n",
            "\n",
            "Transferred 381/417 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/ultralytics/runs/segment/train5', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/sample_dataset_for_YOLOv8/labels/train... 340 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 340/340 [00:46<00:00,  7.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/sample_dataset_for_YOLOv8/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/sample_dataset_for_YOLOv8/labels/val... 88 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 88/88 [00:14<00:00,  6.28it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/sample_dataset_for_YOLOv8/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/ultralytics/runs/segment/train5/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/ultralytics/runs/segment/train5\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/30      5.42G      1.466      4.113      2.908      1.592         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:09<00:00,  2.37it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.977      0.159      0.548      0.385      0.961      0.151      0.479      0.228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/30      5.32G      1.106      2.339      1.335      1.309         17        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.01it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.957      0.564      0.637       0.46      0.929      0.542      0.599       0.28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/30      5.27G      1.121      2.142      1.197      1.283         33        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.21it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.907      0.591      0.797      0.509      0.919      0.571      0.794      0.393\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/30       5.4G       1.03      1.985      1.027      1.223         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.944      0.711      0.836      0.621      0.934      0.699       0.81      0.435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/30      5.42G      1.035      2.004     0.9962      1.235         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.17it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.849        0.7      0.895      0.611      0.807      0.683      0.848      0.445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/30      5.32G     0.9909      1.975     0.9434      1.208         31        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.832      0.786      0.855      0.616      0.829      0.792      0.856      0.473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/30      5.39G     0.9703      1.836     0.9013      1.188         26        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.865      0.852      0.878      0.644      0.847      0.852      0.874      0.514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/30      5.24G      0.951      1.771     0.8528      1.168         19        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.891      0.879      0.911      0.665      0.909      0.864      0.898      0.523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/30      5.27G     0.9597      1.853     0.8555      1.178         21        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.927      0.865      0.904      0.672      0.894       0.83      0.866      0.491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/30      5.32G     0.9143      1.752     0.7984      1.175         25        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.894      0.913      0.897      0.643      0.882      0.902      0.883      0.501\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/30      5.34G     0.9451      1.798     0.8016      1.187         32        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.908      0.878      0.913      0.679      0.918      0.871      0.909      0.534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/30      5.38G     0.9105      1.672     0.7549      1.152         29        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.883      0.909      0.913      0.665      0.862      0.886      0.883      0.503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/30      5.25G     0.8769       1.68     0.7317      1.147         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.903      0.924      0.921       0.67      0.886      0.905      0.902      0.538\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/30      5.38G      0.879      1.694     0.7071      1.136         37        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.28it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.884       0.83      0.868      0.642      0.867      0.815      0.831       0.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/30      5.31G     0.8568      1.605     0.6751      1.111         39        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.904      0.933      0.932       0.68      0.925      0.951      0.958      0.563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      16/30      5.28G     0.8465      1.566     0.6523      1.121         28        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.26it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.918      0.919      0.917      0.671      0.925      0.924      0.928      0.529\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      17/30      5.33G      0.827      1.524     0.6433      1.096         34        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.908      0.917      0.912      0.678      0.905      0.917      0.916      0.555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      18/30      5.27G     0.8407      1.505     0.6256       1.11         23        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.27it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.863      0.881      0.875      0.657       0.87      0.887      0.885      0.514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      19/30      5.43G      0.819      1.516     0.6244        1.1         36        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.34it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.914      0.902      0.914      0.696       0.92      0.905      0.926       0.55\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      20/30      5.39G     0.8044      1.533      0.599      1.089         24        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.938      0.943      0.948      0.708      0.934      0.939      0.944      0.565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      21/30      5.45G     0.8188      1.464     0.7228      1.131         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:09<00:00,  2.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.949      0.942      0.958      0.705      0.945      0.939       0.95      0.567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      22/30      5.07G     0.7638      1.353     0.6298      1.114         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:05<00:00,  4.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.97it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.936       0.95      0.936      0.688      0.925      0.944      0.936      0.555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      23/30      5.07G     0.7617      1.381      0.608      1.089         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:04<00:00,  4.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.914      0.913      0.934      0.696      0.908      0.911      0.933      0.566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      24/30      5.07G     0.7451      1.317     0.6005      1.089         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:04<00:00,  4.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.938       0.89      0.935      0.702      0.909      0.919      0.937      0.561\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      25/30      5.07G     0.7271      1.299     0.5853      1.099         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:04<00:00,  4.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.932      0.943      0.953      0.698       0.94      0.947      0.958       0.57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      26/30      5.07G     0.7356      1.322     0.5615       1.08         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:04<00:00,  4.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.905      0.931      0.927      0.694      0.917      0.917      0.927      0.559\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      27/30      5.07G     0.7031      1.249     0.5406      1.063         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:04<00:00,  4.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.932      0.936       0.94      0.717      0.936      0.939      0.947      0.585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      28/30      5.07G     0.7077       1.27     0.5298      1.064         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:04<00:00,  4.43it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.925      0.909      0.913      0.705       0.93      0.913      0.924      0.566\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      29/30      5.07G     0.6772      1.202     0.5181      1.053         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:04<00:00,  4.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.964      0.924      0.946      0.709      0.952      0.952      0.954      0.585\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      30/30      5.05G     0.6646      1.176     0.5043      1.036         12        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 22/22 [00:04<00:00,  4.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.926      0.902      0.914      0.702      0.926      0.909      0.917      0.563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "30 epochs completed in 0.060 hours.\n",
            "Optimizer stripped from /content/ultralytics/runs/segment/train5/weights/last.pt, 6.8MB\n",
            "Optimizer stripped from /content/ultralytics/runs/segment/train5/weights/best.pt, 6.8MB\n",
            "\n",
            "Validating /content/ultralytics/runs/segment/train5/weights/best.pt...\n",
            "Ultralytics YOLOv8.1.20 ğŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8n-seg summary (fused): 195 layers, 3258649 parameters, 0 gradients\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         88        264      0.936      0.939      0.946      0.718      0.933      0.936      0.946      0.584\n",
            "                eyelid         88         88      0.994          1      0.995      0.852      0.994          1      0.995      0.752\n",
            "                  iris         88         88      0.994          1      0.995      0.882      0.983      0.989      0.985      0.592\n",
            "                 pupil         88         88       0.82      0.818      0.847       0.42       0.82      0.818      0.856       0.41\n",
            "Speed: 0.5ms preprocess, 2.1ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1m/content/ultralytics/runs/segment/train5\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Inference trained model (éˆ´æœ¨ãã‚“)**"
      ],
      "metadata": {
        "id": "io6l7r-BiaIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#æœ¬ä½“\n",
        "from ultralytics import YOLO\n",
        "# ã‚³ãƒ³ãƒ•ã‚£ã‚°ã¯å­¦ç¿’æ™‚ã¨åŒã˜ã‚³ãƒ³ãƒ•ã‚£ã‚°ã§ã‚ˆã„\n",
        "#model = YOLO(\"/Users/ryuka/workspace/Python/Image_AI/yolov8/ultralytics-main/ultralytics/cfg/models/v8/myyolov8.yaml\")  # build a new model from scratch\n",
        "\n",
        "# bestã®ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ã†,trainã®ã‚¦ã‚§ã‚¤ãƒˆã®ãƒ™ã‚¹ãƒˆã®ãƒ‘ã‚¹ã‚’æŒ‡å®š\n",
        "model = YOLO(\"/content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/sample_dataset_for_YOLOv8/last.pt\")  # load a pretrained model (recommended for training)\n",
        "\n",
        "#ã€€ç”»åƒã®ãƒ‘ã‚¹ã‚’æŒ‡å®š\n",
        "img_path = \"/content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/testset(patient)/æ­£å¸¸_å°å…_1.jpg\"\n",
        "results = model(img_path ,save=True, save_txt=True)  # predict on an image"
      ],
      "metadata": {
        "id": "ZjwKVV7EifpJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bd90a19-b45d-4983-f304-6ae9d0fe1658"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "image 1/1 /content/drive/MyDrive/Deep_learning/YOLACT_Mobius_ocular_dataset/testset(patient)/æ­£å¸¸_å°å…_1.jpg: 640x640 1 eyelid, 1 iris, 1 pupil, 17.0ms\n",
            "Speed: 1.5ms preprocess, 17.0ms inference, 4.8ms postprocess per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1m/content/ultralytics/runs/segment/predict2\u001b[0m\n",
            "1 label saved to /content/ultralytics/runs/segment/predict2/labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ç¨®é¡ã‚’èª¿ã¹ã‚‹\n",
        "for e in results[0].boxes.cls.cpu():\n",
        "  print(e, model.names[int(e)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu644_dBtvHE",
        "outputId": "a5452506-16a2-418e-b62b-ba0c35002429"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.) iris\n",
            "tensor(0.) eyelid\n",
            "tensor(2.) pupil\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results[0].boxes"
      ],
      "metadata": {
        "id": "VFBjNKCctvJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results[0].masks"
      ],
      "metadata": {
        "id": "pLDUCeSVuMyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import numpy as np\n",
        "img = cv2.imread(img_path)\n",
        "\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "aV-ITQRyuMz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, e in enumerate(results[0].masks.cpu().xy) :\n",
        "  pos = e.reshape((-1,1,2)).astype(np.int32)\n",
        "  cv2.polylines(img, [pos], isClosed=True, color= (255, 0, 32*i), thickness=2)\n",
        "  # cv2.fillPoly(img, [pos], color= (255, 0, 32*i))\n",
        "\n",
        "cv2_imshow(img)"
      ],
      "metadata": {
        "id": "ZSetsxx1uM1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1sx-Ir-juM3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oq7nxtCXtvLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = results[0] #æ¤œå‡ºã—ãŸçµæœã‚’resultã«æ ¼ç´\n",
        "item=len(result.boxes) #æ¤œå‡ºã—ãŸã‚¢ã‚¤ãƒ†ãƒ ã®æ•°ã‚’å‡ºã™\n",
        "print(item)\n",
        "box = result.boxes[0] #æ¤œå‡ºã—ãŸã‚¢ã‚¤ãƒ†ãƒ ã®No.0ã®Boxã®æƒ…å ±\n",
        "\n",
        "class_id = result.names[box.cls[0].item()]\n",
        "cords = box.xyxy[0].tolist()\n",
        "cords = [round(x) for x in cords]\n",
        "conf = round(box.conf[0].item(), 2)\n",
        "\n",
        "print(\"Object type:\", class_id)\n",
        "print(\"Coordinates:(å››æ¨äº”å…¥å¾Œã®å€¤)\", cords)\n",
        "print(\"Probability:\", conf)"
      ],
      "metadata": {
        "id": "tueGZQPdilmX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1a9cd1b-1e23-45ed-fa47-1411c344584c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "Object type: iris\n",
            "Coordinates:(å››æ¨äº”å…¥å¾Œã®å€¤) [170, 215, 410, 419]\n",
            "Probability: 0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(box)"
      ],
      "metadata": {
        "id": "ANIH10tcs04P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = results[0] #æ¤œå‡ºã—ãŸçµæœã‚’resultã«æ ¼ç´\n",
        "idem=len(result.boxes) #æ¤œå‡ºã—ãŸã‚¢ã‚¤ãƒ†ãƒ ã®æ•°ã‚’å‡ºã™\n",
        "print(idem)\n",
        "box = result.boxes[1] #æ¤œå‡ºã—ãŸã‚¢ã‚¤ãƒ†ãƒ ã®No.0ã®Boxã®æƒ…å ±\n",
        "\n",
        "class_id = result.names[box.cls[0].item()]\n",
        "cords = box.xyxy[0].tolist()\n",
        "cords = [round(x) for x in cords]\n",
        "conf = round(box.conf[0].item(), 2)\n",
        "\n",
        "print(\"Object type:\", class_id)\n",
        "print(\"Coordinates:(å››æ¨äº”å…¥å¾Œã®å€¤)\", cords)\n",
        "print(\"Probability:\", conf)"
      ],
      "metadata": {
        "id": "xNWePP0Wip_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "900cd6d3-a664-446d-cef7-12fd89e82b0c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "Object type: eyelid\n",
            "Coordinates:(å››æ¨äº”å…¥å¾Œã®å€¤) [127, 210, 555, 436]\n",
            "Probability: 0.93\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#æœ¬ä½“\n",
        "result = results[0]\n",
        "itemnums = len(result.boxes)\n",
        "for i in range(itemnums):\n",
        "    box = result.boxes[i]\n",
        "    class_id = result.names[box.cls[0].item()]\n",
        "    cords = box.xyxy[0].tolist()\n",
        "    cords = [round(x) for x in cords]\n",
        "    if class_id == 'eyelid':\n",
        "        bunsi = cords[3]-cords[1]\n",
        "    elif class_id == 'iris':\n",
        "        bunbo = cords[2]-cords[0]\n",
        "ans = 1.2*bunsi/bunbo\n",
        "print('ç¼è£‚å¾„ã¯{:.2f}'.format(ans),'ãã¨äºˆæ¸¬ã•ã‚Œã¾ã™ï¼')"
      ],
      "metadata": {
        "id": "2BsigtPdiqlq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed9d95ce-c110-43af-fa8c-1340627e66ae"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ç¼è£‚å¾„ã¯1.13 ãã¨äºˆæ¸¬ã•ã‚Œã¾ã™ï¼\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "model =  YOLO('yolov8n-seg.pt')\n",
        "\n",
        "# Run inference on 'bus.jpg'\n",
        "results = model('/content/ultralytics/2019H-6_after_2.jpg')  # results list\n",
        "\n",
        "# Show the results\n",
        "for r in results:\n",
        "    im_array = r.plot(masks = True)  # plot a BGR numpy array of predictions\n",
        "    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image\n",
        "    im.show()  # show image\n",
        "    im.save('results2.jpg')  # save image"
      ],
      "metadata": {
        "id": "gVQK71xLiuHg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "aadc6cda-63a0-4481-ead7-03def33f49ff"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "/content/ultralytics/2019H-6_after_2.jpg does not exist",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-3566804f6e57>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Run inference on 'bus.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/ultralytics/2019H-6_after_2.jpg'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# results list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Show the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ultralytics/ultralytics/engine/model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, stream, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0multralytics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencapsulated\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mResults\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \"\"\"\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ultralytics/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprompts\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"set_prompts\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for SAM-type models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_prompts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_cli\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     def track(\n",
            "\u001b[0;32m/content/ultralytics/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, source, model, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# merge list of Result into one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_cli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mgenerator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;31m# Issuing `None` to a generator fires it up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ultralytics/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36mstream_inference\u001b[0;34m(self, source, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# for thread-safe inference\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0;31m# Setup source every time predict is called\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup_source\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;31m# Check if save_dir/ label file exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ultralytics/ultralytics/engine/predictor.py\u001b[0m in \u001b[0;36msetup_source\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         )\n\u001b[0;32m--> 230\u001b[0;31m         self.dataset = load_inference_source(\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvid_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         )\n",
            "\u001b[0;32m/content/ultralytics/ultralytics/data/build.py\u001b[0m in \u001b[0;36mload_inference_source\u001b[0;34m(source, vid_stride, buffer)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadPilAndNumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLoadImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvid_stride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvid_stride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;31m# Attach source types to the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/ultralytics/ultralytics/data/loaders.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, vid_stride)\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# files (relative to *.txt file parent)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{p} does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mIMG_FORMATS\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: /content/ultralytics/2019H-6_after_2.jpg does not exist"
          ]
        }
      ]
    }
  ]
}